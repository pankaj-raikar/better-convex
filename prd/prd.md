# LearnFlow AI: Complete Implementation Guide

## Full PRD + Spec with Enhanced Recommendations

**Document Version:** 3.1 (Updated with Best Practices & Gap Recommendations)  
**Date:** November 15, 2025  
**Purpose:** Single source of truth for building LearnFlow AI with enhanced chat UX, agent orchestration, and learning effectiveness  
**Status:** Ready to implement  
**Changes from v3.0:** Added 7 enhancement categories, better learning outcome measurement, safety mechanisms, collaboration features

---

# TABLE OF CONTENTS

1. [Executive Summary & Vision](#1-executive-summary--vision)
   1. [Vision](#11-vision)
   2. [Mission](#12-mission)
   3. [Key Differentiators](#13-key-differentiators)
2. [Product Overview & Positioning](#2-product-overview--positioning)
   1. [Target Users](#21-target-users)
   2. [Core Features](#22-core-features)
3. [15-Agent Architecture](#3-15-agent-architecture)
   1. [Agent Descriptions](#31-agent-descriptions)
   2. [Agent Interactions](#32-agent-interactions)
4. [UI/UX Architecture](#4-uiux-architecture)
   1. [Interface Components](#41-interface-components)
   2. [User Flows](#42-user-flows)
5. [Purpose-Based System](#5-purpose-based-system)
   1. [System Design](#51-system-design)
   2. [Implementation Details](#52-implementation-details)
6. [Tech Stack & Infrastructure](#6-tech-stack--infrastructure)
   1. [Frontend](#61-frontend)
   2. [Backend](#62-backend)
   3. [AI/ML](#63-aiml)
7. [Database Schema](#7-database-schema)
   1. [Core Tables](#71-core-tables)
   2. [Relationships](#72-relationships)
8. [12-Week Implementation Roadmap](#8-12-week-implementation-roadmap)
   1. [Phase 0: Foundation](#81-phase-0-foundation)
   2. [Phase 1-4: Core Implementation](#82-phase-1-4-core-implementation)
9. [Step-by-Step Implementation Guide](#9-step-by-step-implementation-guide)
   1. [Setup Instructions](#91-setup-instructions)
   2. [Development Workflow](#92-development-workflow)
10. [Testing & Quality Assurance](#10-testing--quality-assurance)
    1. [Test Cases](#101-test-cases)
    2. [QA Process](#102-qa-process)
11. [Deployment & Launch](#11-deployment--launch)
    1. [Staging](#111-staging)
    2. [Production](#112-production)
12. [Success Metrics & KPIs](#12-success-metrics--kpis)
    1. [Performance Metrics](#121-performance-metrics)
    2. [Business Metrics](#122-business-metrics)
13. [Additional Recommendations (v3.1)](#13-additional-recommendations-v31)
    1. [Enhanced Chat Interface UX](#131-enhanced-chat-interface-ux)
    2. [Learning Outcome Measurement](#132-learning-outcome-measurement)
    3. [Safety & Content Grounding](#133-safety--content-grounding)
    4. [Curriculum Graph & Ontology](#134-curriculum-graph--ontology)
    5. [Teacher Oversight & Classroom Mode](#135-teacher-oversight--classroom-mode)
    7. [Accessibility Extensions](#137-accessibility-extensions)

---

# 1. EXECUTIVE SUMMARY & VISION

## 1.1 Vision

Build **LearnFlow AI**, a **Knowledge Personalization Engine** that uses 15 specialized AI agents orchestrated by Mastra to transform ANY educational document into personalized learning materialâ€”tailored to each student's language, learning ability, and learning style.

Unlike competitors offering one-size-fits-all solutions, LearnFlow orchestrates agents intelligently based on user PURPOSE (not prescriptive personas), delivers real-time reactive UI updates (<1s), and supports three critical user segments:

1. **Interview & Placement Prep** (Engineering students)
2. **Accessibility & Inclusive Learning** (Students with dyslexia, ADHD)
3. **Language & Cultural Bridge** (Vernacular background students)

## 1.2 Mission

**Democratize quality education** by removing three critical barriers:

1. **Time to Mastery**: Reduce study time by 60% through AI-personalized learning
2. **Accessibility**: Make learning materials universally accessible regardless of ability or language
3. **Engagement**: Increase knowledge retention through adaptive, interactive content

## 1.3 Key Differentiators

| Feature           | LearnFlow AI                                 | Competitors                   |
| ----------------- | -------------------------------------------- | ----------------------------- |
| Personalization   | Dynamic agent orchestration based on purpose | Static content delivery       |
| Speed             | Sub-second response times                    | Multi-second delays           |
| Accessibility     | Built-in from day one                        | Added as afterthought         |
| Customization     | Deep customization of learning paths         | Limited customization options |
| Real-time Updates | Live content adaptation                      | Manual content updates        |

---

[Previous sections continue with proper hierarchical structure...]

---

# 13. ADDITIONAL RECOMMENDATIONS (v3.1)

## 13.1 Enhanced Chat Interface UX

### 13.1.1 Token-by-Token Streaming

**Why:** Users see content appear instantly, creating perception of speed

**Implementation:**

```typescript
// Backend: Stream at token level
async function streamChatResponse(message: string) {
  const encoder = new TextEncoder();
  const stream = new ReadableStream({
    async start(controller) {
      const startTime = Date.now();
      let tokenCount = 0;

      for await (const token of agentTokenStream) {
        tokenCount++;
        const elapsed = Date.now() - startTime;

        // Emit token with timing
        controller.enqueue(
          encoder.encode(
            `data: ${JSON.stringify({
              token,
              tokenCount,
              elapsedMs: elapsed,
              type: "delta",
            })}\n\n`
          )
        );

        // Throttle to avoid overwhelming client
        if (tokenCount % 5 === 0) {
          await new Promise((resolve) => setTimeout(resolve, 10));
        }
      }

      controller.close();
    },
  });

  return stream;
}

// Frontend: Display token-by-token
function TokenStreamDisplay({ stream }) {
  const [tokens, setTokens] = useState([]);
  const [ttfb, setTtfb] = useState(null);

  useEffect(() => {
    const startTime = Date.now();
    let firstToken = true;

    const eventSource = new EventSource(stream);

    eventSource.addEventListener("message", (event) => {
      const { token, elapsedMs } = JSON.parse(event.data);

      if (firstToken) {
        setTtfb(elapsedMs);
        firstToken = false;
      }

      setTokens((prev) => [...prev, token]);
    });

    return () => eventSource.close();
  }, [stream]);

  return (
    <div>
      <div className="ttfb-badge">âš¡ TTFB: {ttfb}ms</div>
      <div className="tokens-display">
        {tokens.map((token, i) => (
          <span key={i} className="token fade-in">
            {token}
          </span>
        ))}
      </div>
    </div>
  );
}
```

**Target:** TTFB <800ms (vs <1500ms requirement)

### 13.1.2 Suggestion Chips with Context-Awareness

**Why:** Guides user without interrupting flow

**Implementation:**

```typescript
// Generate contextual suggestions
async function generateSuggestions(
  documentContent: string,
  chatHistory: Message[],
  currentSection: string,
  userPurpose: "interview" | "accessibility" | "language"
) {
  const context = {
    lastUserQuery: chatHistory[chatHistory.length - 1].content,
    currentSection,
    documentTopic: extractTopic(documentContent),
    purpose: userPurpose,
  };

  // Generate 5 suggestions based on:
  // 1. Natural follow-ups to last question
  // 2. Related concepts in document
  // 3. Purpose-specific needs
  // 4. User learning level

  const suggestions = [
    {
      label: "Show me the code",
      action: "regenerate",
      payload: { format: "code" },
    },
    {
      label: "Make it simpler",
      action: "refine",
      payload: { instruction: "simplify" },
    },
    {
      label: "Add diagram",
      action: "add_agent",
      payload: { agent: "Diagram" },
    },
    {
      label: "Create quiz",
      action: "generate_quiz",
      payload: { scope: "section" },
    },
    {
      label: "Translate to [translate:à¤¹à¤¿à¤‚à¤¦à¥€]",
      action: "toggle_language",
      payload: { lang: "hi" },
    },
  ];

  return suggestions;
}

// Frontend component
function SuggestionChips({ suggestions, onSuggestionClick }) {
  return (
    <div className="suggestion-rail">
      {suggestions.map((sugg, i) => (
        <button
          key={i}
          className="chip"
          onClick={() => onSuggestionClick(sugg)}
        >
          ğŸ’¡ {sugg.label}
        </button>
      ))}
    </div>
  );
}
```

### 13.1.3 Message Feedback & Quality Signals

**Why:** Collect data on which agent responses work best

**Implementation:**

```typescript
// Feedback buttons per message
function ChatMessage({ message, messageId }) {
  const [feedback, setFeedback] = useState(null);

  async function submitFeedback(rating: "helpful" | "meh" | "incorrect") {
    await recordFeedback({
      messageId,
      rating,
      agent: message.agent,
      timestamp: Date.now(),
    });
    setFeedback(rating);
  }

  return (
    <div className="message">
      <div className="message-content">{message.content}</div>

      <div className="message-feedback">
        <span className="agent-tag">{message.agent}</span>
        <span className="feedback-buttons">
          <button
            onClick={() => submitFeedback("helpful")}
            className={feedback === "helpful" ? "selected" : ""}
          >
            ğŸ‘ Helpful
          </button>
          <button
            onClick={() => submitFeedback("meh")}
            className={feedback === "meh" ? "selected" : ""}
          >
            ğŸ˜ Okay
          </button>
          <button
            onClick={() => submitFeedback("incorrect")}
            className={feedback === "incorrect" ? "selected" : ""}
          >
            ğŸ‘ Not helpful
          </button>
        </span>
      </div>
    </div>
  );
}

// Aggregate feedback
async function aggregateQualityMetrics() {
  const metrics = {
    "Code Agent": {
      helpful: 856,
      meh: 124,
      incorrect: 20,
      helpful_pct: 0.87,
    },
    "Accessibility Agent": {
      helpful: 943,
      meh: 45,
      incorrect: 12,
      helpful_pct: 0.95,
    },
    // ... other agents
  };

  // Identify which agents need improvement
  const agentsUnderPerforming = Object.entries(metrics).filter(
    ([_, m]) => m.helpful_pct < 0.8
  );

  // Alert: Code Agent at 87%, consider retuning prompts

  return metrics;
}
```

## 13.2 Learning Outcome Measurement

### 13.2.1 Pre/Post Quiz Testing

**Why:** Measure actual learning impact, not just engagement

**Implementation:**

```typescript
// Before user starts document
async function generatePreQuiz(docId: string) {
  return await quizAgent.generate({
    scope: "document",
    type: "diagnostic",
    difficulty: "medium",
    questionCount: 5,
  });
}

// After user finishes
async function generatePostQuiz(docId: string) {
  // Same questions, different order
  return await quizAgent.generate({
    scope: "document",
    type: "assessment",
    difficulty: "medium",
    questionCount: 5,
  });
}

// Dashboard showing improvement
interface LearningOutcome {
  docId: string;
  preScore: number; // 0-100
  postScore: number; // 0-100
  delta: number; // +30 means 30% improvement
  timeSpent: number; // minutes
  agentsUsed: string[];
  comprehensionGain: "low" | "medium" | "high";
  nps: number; // 0-10 user satisfaction
}

// Track over time
interface LearningCurve {
  user_id: string;
  documents: LearningOutcome[];
  averageDelta: number; // Average improvement across docs
  trend: "improving" | "stable" | "declining";
  topPerformingAgents: string[]; // Which agents help most
  learningVelocity: number; // Documents per week
}
```

### Agent Performance Tied to Learning Gains

**Why:** Measure which agents actually help students learn

**Implementation:**

```typescript
// For each agent, track impact on learning
interface AgentImpactMetrics {
  agent: string;
  documentsUsed: number;
  averageComprensionDelta: number; // Average student improvement
  userHelpfulnessRating: number; // Feedback score 0-1
  accuracy: number; // Manual grading of outputs
  adoptionRate: number; // % of users who use this agent
}

// Example metrics:
// Code Agent: +15% comprehension delta, 87% helpful rating
// Accessibility Agent: +22% (for dyslexia users), 95% helpful
// Translation Agent: +18% (for language bridge users), 91% helpful

// Use to improve:
// - Which agent needs retuning?
// - Which prompts are most effective?
// - Should we add new agent or improve existing one?
```

## 3. Safety & Content Grounding

### Citation Requirement for All Factual Claims

**Why:** Prevent hallucinations, enable trust

**Implementation:**

Embedding & verification pipeline:

1. Index source doc chunks with `text-embedding-3-large` (chunk size ~800 tokens, 100 token overlap)
2. Extract candidate claims via regex + NLP (sentence split, detect numeric/data/code refs)
3. For each claim compute cosine similarity against chunk embeddings
   - If similarity â‰¥0.82 â†’ high-confidence citation (attach chunk id)
   - If 0.74â€“0.81 â†’ attempt multi-chunk merge then re-evaluate; if still <0.82 mark low-confidence
   - If <0.74 â†’ send claim + top 3 chunks to LLM verification prompt
4. LLM returns: `supported|needs_refine|unsourced`
5. Unsourced claims â†’ regeneration with explicit citation instruction or flag for manual review
6. Store per-claim audit record: `{claim, status, sourceChunkIds, confidence}`

Regeneration rule: any message with â‰¥1 unsourced claim triggers `regenerate_with_citations` once; second failure â†’ surface warning badge.

Metrics tracked: citationCoveragePct (claims with â‰¥1 citation), avgCitationConfidence, unsourcedClaimRate.

```typescript
// Every factual claim must have source
function validateAgentOutput(output: string, source: Document) {
  const claims = extractFactualClaims(output);

  for (const claim of claims) {
    const citation = findSourceInDocument(claim, source);

    if (!citation) {
      // Flag for manual review or regenerate
      return {
        valid: false,
        unsourcedClaims: [claim],
        action: "regenerate_with_citations",
      };
    }
  }

  return { valid: true, citationsPresent: true };
}

// Frontend: Show inline citations
function CitedContent({ content, citations }) {
  return (
    <div className="cited-content">
      {content.split("[citation:").map((part, i) => {
        if (i === 0) return <span key={i}>{part}</span>;

        const [citId, text] = part.split("]", 2);
        const citation = citations[citId];

        return (
          <span key={i}>
            <span className="citation-hover">
              {text}
              <span className="citation-tooltip">
                Page {citation.page}: {citation.snippet}
              </span>
            </span>
          </span>
        );
      })}
    </div>
  );
}
```

### Plagiarism Detection Agent

**Why:** Prevent content copying, ensure original work

**Implementation:**

```typescript
// New Agent: Plagiarism Detector
export const plagiarismAgent = new Agent({
  name: "PlagiarismDetector",
  model: openai("gpt-4"),
  instructions: `
    You are a plagiarism detection agent.
    Check if generated content is:
    1. Copied verbatim from source
    2. Paraphrased but not substantially transformed
    3. Properly synthesized and original
    
    Flag any suspicious content.
  `,
  tools: [checkAgainstSource, searchOnlineDatabase, analyzeParaphrase],
});

// Integration in Orchestrator
async function validateBeforeOutput(agentOutput: string, sourceDoc: Document) {
  const plagiarismCheck = await plagiarismAgent.run({
    output: agentOutput,
    source: sourceDoc,
  });

  if (plagiarismCheck.isSuspicious) {
    // Regenerate with instruction to paraphrase differently
    return await regenerateWithGuard(agentOutput, sourceDoc);
  }

  return agentOutput;
}
```

### Bias Check Agent (Prototype)

**Why:** Ensure educational fairness, prevent stereotyping

**Implementation:**

```typescript
// New Agent: Bias Checker (early prototype)
export const biasCheckAgent = new Agent({
  name: "BiasChecker",
  model: openai("gpt-4"),
  instructions: `
    Analyze for potential biases:
    1. Gender stereotyping
    2. Cultural insensitivity
    3. Difficulty assumptions
    4. Example representation diversity
    
    Flag for manual review if found.
  `,
});

// Before delivery
async function checkForBias(output: string) {
  const biasReport = await biasCheckAgent.run({ output });

  if (biasReport.flaggedIssues.length > 0) {
    // Route to educator for review
    await routeForManualReview({
      content: output,
      issues: biasReport.flaggedIssues,
      reviewType: "bias",
    });

    // Offer to regenerate
    return {
      status: "pending_review",
      regenerateOption: true,
    };
  }

  return { status: "approved", safe: true };
}
```

## 4. Curriculum Graph & Ontology Integration

### Subject-Topic Ontology

**Why:** Map knowledge, suggest prerequisites, enable curriculum awareness

**Implementation:**

```typescript
// Knowledge graph structure
const curriculumOntology = {
  "Computer Science": {
    "Data Structures": {
      Arrays: { complexity: 1, prereqs: [] },
      "Linked Lists": { complexity: 1, prereqs: ["Arrays"] },
      "Binary Search Trees": {
        complexity: 3,
        prereqs: ["Arrays", "Linked Lists"],
      },
      "Graph Structures": {
        complexity: 3,
        prereqs: ["Arrays", "Linked Lists"],
      },
      Heaps: { complexity: 2, prereqs: ["Arrays"] },
    },
    Algorithms: {
      Sorting: { complexity: 2, prereqs: ["Arrays"] },
      Searching: { complexity: 2, prereqs: ["Arrays"] },
      "Dynamic Programming": {
        complexity: 4,
        prereqs: ["Recursion", "Sorting"],
      },
    },
    "System Design": {
      Databases: {
        complexity: 4,
        prereqs: ["Data Structures", "Algorithms"],
      },
      Scalability: {
        complexity: 5,
        prereqs: ["Databases", "Networking"],
      },
    },
  },
  Mathematics: {
    "Linear Algebra": {
      Vectors: { complexity: 1, prereqs: [] },
      Matrices: { complexity: 2, prereqs: ["Vectors"] },
      Eigenvalues: { complexity: 3, prereqs: ["Matrices"] },
    },
  },
};

// Map document to ontology
async function mapDocumentToCurriculum(docId: string) {
  const content = await getDocumentContent(docId);
  const concepts = extractConcepts(content);

  const mapping = concepts.map((concept) => {
    const node = findInOntology(concept);
    return {
      concept,
      subject: node.subject,
      topic: node.topic,
      complexity: node.complexity,
      prerequisites: node.prereqs,
    };
  });

  return mapping;
}

// Suggest prerequisites
async function suggestPrerequisites(docId: string) {
  const mapping = await mapDocumentToCurriculum(docId);
  const prerequisites = new Set();

  for (const item of mapping) {
    for (const prereq of item.prerequisites) {
      prerequisites.add(prereq);
    }
  }

  return Array.from(prerequisites);
}

// In UI: Show prerequisite map
function PrerequisiteMap({ docId }) {
  const prerequisites = useQuery(api.curriculum.getPrerequisites, { docId });

  return (
    <div className="prerequisite-section">
      <h3>Before this document, consider:</h3>
      {prerequisites.map((prereq) => (
        <button key={prereq} className="prereq-chip">
          ğŸ“š {prereq}
          <span className="arrow">â†’</span>
        </button>
      ))}
    </div>
  );
}
```

## 5. Teacher Oversight & Classroom Mode

### Educator Portal

**Why:** Enable classroom integration, maintain instructor control

**Implementation:**

```typescript
// New routes for educators
/educator/dashboard
/educator/class/[id]
/educator/student/[id]/progress
/educator/content-review

// Educator permissions
interface EducatorPermissions {
  viewStudentChats: boolean;
  flagContent: boolean;
  approveContent: boolean;
  setClassroomRulesAgent: boolean;
  generateClassReports: boolean;
  controlAgentAccess: boolean;
}

// Classroom mode: guardrails
interface ClassroomSettings {
  allowedAgents: string[];          // Which agents can be used
  requireApprovalFor: string[];     // Which agents need review
  contentFilters: string[];         // Block certain content types
  timeLimit: number;                // Minutes per session
  feedbackLevel: 'full'|'summary'|'none';
}

// Example: Math class setup
const mathClassroomConfig: ClassroomSettings = {
  allowedAgents: [
    'Mathematician',
    'Diagram',
    'Quiz',
    'Accessibility'
  ],
  requireApprovalFor: [
    'Code Agent'  // No coding in math class
  ],
  contentFilters: [],
  timeLimit: 60,
  feedbackLevel: 'summary'
};

// Teacher dashboard
function EducatorDashboard({ classId }) {
  const students = useQuery(api.educator.getClassStudents, { classId });

  return (
    <div className="educator-dashboard">
      <h2>Class Progress</h2>
      {students.map(student => (
        <StudentCard
          key={student.id}
          student={student}
          stats={{
            docsCompleted: student.docsCompleted,
            avgLearningGain: student.avgDelta,
            timeSpent: student.totalMinutes,
            flaggedContent: student.flaggedMessages?.length || 0
          }}
        />
      ))}
    </div>
  );
}
```


## 7. User Research & Iterative Design

### Usability Studies

**Why:** Validate assumptions, catch UX issues early

**Implementation:**

```typescript
// Monthly usability study: 5-8 learners
interface UsabilityStudy {
  month: string;
  participants: number;
  duration: number; // hours per participant
  focusAreas: string[]; // e.g., 'chat UX', 'suggestions', 'export'
  keyFindings: string[];
  urgentIssues: string[];
  recommendations: string[];
}

// Weekly telemetry dashboard
interface TelemetryMetrics {
  chatDropOffRate: number; // % who stop mid-conversation
  dropOffPoints: string[]; // "After first message", "After 3 messages"
  avgMessagesPerSession: number;
  userConfusion: {
    topic: string;
    frequency: number;
    resolution: string;
  }[];
  featureAdoption: {
    feature: string;
    usage: number;
    satisfaction: number;
  }[];
}

// Telemetry dashboard
function TelemetryDashboard() {
  return (
    <div className="telemetry">
      <h2>Weekly Metrics</h2>

      <Card>
        <h3>Chat Drop-Off Analysis</h3>
        <Chart data={dropOffData} />
        <p>â„¹ï¸ Users often leave after "Suggest next topic" feature</p>
        <button>View Issues</button>
      </Card>

      <Card>
        <h3>Feature Adoption</h3>
        {featureAdoption.map((f) => (
          <FeatureMetric
            key={f.feature}
            feature={f.feature}
            usage={f.usage}
            satisfaction={f.satisfaction}
          />
        ))}
      </Card>

      <Card>
        <h3>User Quotes</h3>
        <Quote>"I didn't understand what the diagram was showing"</Quote>
        <Quote>"The bilingual toggle was confusing at first"</Quote>
      </Card>
    </div>
  );
}
```

### Continuous Feedback Loop

**Why:** Live feedback in UI, rapid iteration

**Implementation:**

```typescript
// In-app feedback collection
function LiveFeedbackWidget() {
  return (
    <div className="feedback-widget">
      <p>Was this helpful?</p>
      <div className="emoji-reaction">
        <button onClick={() => recordFeedback(5)}>ğŸ˜</button>
        <button onClick={() => recordFeedback(4)}>ğŸ˜Š</button>
        <button onClick={() => recordFeedback(3)}>ğŸ˜</button>
        <button onClick={() => recordFeedback(2)}>ğŸ˜•</button>
        <button onClick={() => recordFeedback(1)}>ğŸ˜</button>
      </div>

      <textarea placeholder="Optional: Tell us why..." />

      <button>Send Feedback</button>
    </div>
  );
}

// Aggregate into insights
async function generateInsights() {
  const feedback = await getFeedbackFromLastWeek();

  return {
    averageRating: 4.2, // out of 5
    topComplaint: "Diagram explanations unclear",
    topPraise: "Bilingual support amazing",
    actionItems: [
      "Improve Diagram Agent prompts",
      "Expand Translation Agent glossary",
    ],
  };
}
```

## 8. Accessibility Extensions

### Screen Reader Usage Tracking

**Why:** Understand how accessible features are used

**Implementation:**

```typescript
// Track screen reader activity
interface AccessibilityUsage {
  screenReaderEnabled: boolean;
  screenReaderType: "NVDA" | "JAWS" | "VoiceOver" | "TalkBack";
  accessibilityFeaturesUsed: string[];
  dyslexiaFontUsed: boolean;
  audioUsagePercent: number;
  highContrastMode: boolean;
  focusIndicatorsVisible: boolean;
}

// Dashboard for accessibility analytics
function AccessibilityDashboard() {
  const usage = useQuery(api.analytics.getAccessibilityUsage);

  return (
    <div className="accessibility-dashboard">
      <h2>Accessibility Feature Usage</h2>

      <Card>
        <h3>Dyslexia-Friendly Mode</h3>
        <p>{usage.dyslexiaFontUsed}% of users</p>
        <p>Avg session: {usage.dyslexiaAvgTime} minutes</p>
      </Card>

      <Card>
        <h3>Audio Support</h3>
        <p>{usage.audioUsagePercent}% of content consumed via audio</p>
        <p>Most popular speed: {usage.mostPopularSpeed}x</p>
      </Card>

      <Card>
        <h3>Screen Reader Usage</h3>
        <p>{usage.screenReaderEnabled}% use screen readers</p>
        <p>Most used: {usage.screenReaderType}</p>
      </Card>
    </div>
  );
}
```

### Dynamic TTS Adaptation

**Why:** Auto-optimize based on user behavior

**Implementation:**

```typescript
// If user repeats same segment â†’ slow down
async function adaptTTSSpeed(userId: string, segmentId: string) {
  const userBehavior = await getUserBehaviorOnSegment(userId, segmentId);

  if (userBehavior.replayCount > 3) {
    // User is replaying this segment 3+ times
    // â†’ They probably struggle with it
    // â†’ Slow down TTS for this user

    return {
      recommendation: "slower_speed",
      newSpeed: 0.75,
      reason: "High replay rate detected",
    };
  }

  if (userBehavior.pauseAfterWords > 5) {
    // User pauses frequently
    return {
      recommendation: "pause_between_sentences",
      pauseMs: 500,
      reason: "Frequent pause behavior",
    };
  }

  return null;
}

// Auto-highlight confusing phrases for ADHD
async function autoHighlightForADHD(content: string, userId: string) {
  if (!isUserWithADHD(userId)) return content;

  // Analyze complexity, identify hard phrases
  const complexPhrases = identifyComplexity(content);

  // Highlight and simplify inline
  return complexPhrases.map((phrase) => ({
    original: phrase.text,
    highlighted: true,
    simplified: phrase.simplifiedVersion,
  }));
}
```

# UPDATED IMPLEMENTATION ROADMAP (with New Features)

## Phase 0-1: Foundation + Chat (Weeks 1-3) - SAME

## Phase 2: Core Agents (Weeks 4-6) - UPDATED

Add safety checks:

- Citation requirement validation
- Plagiarism detection integration
- Bias check agent (prototype)

## Phase 3: Accessibility (Weeks 7-8) - UPDATED

Expand with measurement:

- Pre/post quiz testing
- Learning outcome tracking
- Agent performance metrics

## Phase 4: Export + Learning Measurement (Week 9) - UPDATED

Add:

- Learning curve dashboard
- Pre/post comparisons
- Agent impact analytics
- User satisfaction (NPS)

## Phase 5: Safety + Curriculum (Week 10) - NEW

**Tasks:**

- Curriculum ontology setup
- Prerequisite mapping
- Citation linking system
- Educator portal MVP
- Classroom settings

**Deliverables:**
âœ… Curriculum graph functional  
âœ… Teachers can view/flag content  
âœ… Citations automatically linked  
âœ… Bias detection running

## Phase 6: Teacher Features (Week 11) - NEW

**Tasks:**

- Educator dashboard
- Student progress viewing
- Content approval workflow
- Classroom configuration UI
- Class report generation

**Deliverables:**
âœ… Teachers can manage classes  
âœ… Classroom mode working  
âœ… Content approval flow functional

## Phase 7: User Research + Optimization (Week 12) - NEW

**Tasks:**

- Setup usability studies (3-4 participants)
- Deploy telemetry dashboard
- In-app feedback collection
- Screen reader analytics
- Accessibility audits

**Deliverables:**
âœ… Weekly insights dashboard live  
âœ… Feedback collection working  
âœ… Accessibility usage tracked  
âœ… Ready for full usability study

## Phase 8: Q2 Roadmap (After GA)

- Peer sharing (defer; not core)
- Gamification elements
- Advanced prerequisite system

# UPDATED DATABASE SCHEMA (with New Tables)

```typescript
// Add to v3.1 schema:

// Learning outcomes
export const learning_outcomes = defineTable({
  user_id: v.id("users"),
  doc_id: v.id("documents"),
  preQuizScore: v.number(), // 0-100
  postQuizScore: v.number(), // 0-100
  delta: v.number(), // Improvement
  timeSpent: v.number(), // minutes
  userNPS: v.number(), // 0-10
  comprehensionLevel: v.union(
    v.literal("low"),
    v.literal("med"),
    v.literal("high")
  ),
  created_at: v.number(),
})
  .index("user_id")
  .index("doc_id");

// Agent performance tracking
export const agent_performance = defineTable({
  agent: v.string(),
  week: v.string(),
  documentsUsed: v.number(),
  avgComprensionDelta: v.number(), // +15 means +15%
  userHelpfulness: v.number(), // 0-1
  accuracy: v.number(), // Manual rating
  adoptionRate: v.number(), // % of users
  created_at: v.number(),
})
  .index("agent")
  .index("week");

// Curriculum mapping
export const curriculum_mapping = defineTable({
  doc_id: v.id("documents"),
  subject: v.string(), // "Computer Science"
  topic: v.string(), // "Data Structures"
  concepts: v.array(v.string()), // ["BST", "Rotations"]
  prerequisites: v.array(v.string()), // ["Arrays", "Linked Lists"]
  complexity: v.number(), // 1-5
  created_at: v.number(),
})
  .index("doc_id")
  .index("subject")
  .index("topic");

// Content review/approval
export const content_reviews = defineTable({
  content_id: v.string(),
  reviewer_id: v.id("users"), // Teacher who reviewed
  reviewType: v.union(
    v.literal("citation"),
    v.literal("plagiarism"),
    v.literal("bias"),
    v.literal("accuracy")
  ),
  status: v.union(
    v.literal("flagged"),
    v.literal("approved"),
    v.literal("rejected")
  ),
  issues: v.array(v.string()),
  notes: v.string(),
  created_at: v.number(),
})
  .index("content_id")
  .index("reviewer_id");

// Telemetry & usage
export const telemetry_events = defineTable({
  user_id: v.id("users"),
  event: v.string(), // "chat_drop_off", "suggestion_clicked"
  details: v.object(),
  created_at: v.number(),
})
  .index("user_id")
  .index("event");

// User feedback
export const user_feedback = defineTable({
  user_id: v.id("users"),
  type: v.string(), // "helpful", "confusing", "feature_request"
  rating: v.number(), // 1-5 emoji rating
  message: v.string(),
  context: v.string(), // Which feature/message
  created_at: v.number(),
}).index("user_id");

// Classroom/educator settings
export const classroom_config = defineTable({
  educator_id: v.id("users"),
  classroomName: v.string(),
  allowedAgents: v.array(v.string()),
  requireApprovalFor: v.array(v.string()),
  timeLimit: v.number(),
  feedbackLevel: v.string(),
  created_at: v.number(),
}).index("educator_id");
```

# UPDATED SUCCESS METRICS (with Learning Outcomes)

## Learning Effectiveness Metrics (NEW)

| Metric                    | Target            | Measurement               |
| ------------------------- | ----------------- | ------------------------- |
| Pre/Post Quiz Delta       | +25% average      | Test before + after       |
| Comprehension Improvement | 85%+ report gains | User survey               |
| Agent Helpful Rating      | â‰¥80%              | Feedback buttons          |
| Learning Velocity         | 3-5 docs/week     | Usage analytics           |
| Concept Retention         | Repeat < 30 days  | Quiz performance tracking |

## Safety Metrics (NEW)

| Metric               | Target         | Measurement         |
| -------------------- | -------------- | ------------------- |
| Hallucination Rate   | <2%            | Citation validation |
| Plagiarism Detection | 100% accuracy  | Manual spot-check   |
| Bias Flagged         | <5% of content | Bias agent output   |
| Citation Coverage    | 95%+ of claims | Automated check     |

## Educator Adoption (NEW)

| Metric               | Target         | Measurement       |
| -------------------- | -------------- | ----------------- |
| Teachers Registering | 50 by Month 3  | Dashboard signup  |
| Class Creation       | 100 classrooms | Educator platform |
| Content Approvals    | >90% pass      | Review workflow   |
| Educator NPS         | â‰¥40            | Survey            |

# QUICK REFERENCE: NEW FEATURES ADDED IN v3.1

1. âœ… Token-by-token streaming (<800ms TTFB)
2. âœ… Context-aware suggestion chips
3. âœ… Per-message feedback (helpful/meh/incorrect)
4. âœ… Pre/post quiz learning measurement
5. âœ… Agent performance tracking by learning gain
6. âœ… Citation requirements (anti-hallucination)
7. âœ… Plagiarism detection agent
8. âœ… Bias check agent (prototype)
9. âœ… Curriculum graph & ontology
10. âœ… Prerequisite mapping
11. âœ… Educator portal (content review)
12. âœ… Classroom mode with guardrails
13. âœ… (Collaboration deferred to Q2; not core MVP)
14. âœ… Monthly usability studies
15. âœ… Weekly telemetry dashboard
16. âœ… Live in-app feedback collection
17. âœ… Screen reader analytics
18. âœ… Dynamic TTS adaptation
19. âœ… ADHD-friendly auto-highlighting
20. âœ… 8 new database tables

# CONCLUSION: v3.1 is Production-Ready

With these enhancements, you have:

âœ… Better UX (token streaming, smart suggestions)  
âœ… Proven learning outcomes (pre/post testing)  
âœ… Safety mechanisms (citations, plagiarism, bias)  
âœ… Educator support (classroom management)  
âœ… Research-backed design (usability studies)  
âœ… Accessibility excellence (adaptive TTS, ADHD support)  
âœ… Knowledge graph (curriculum awareness)

You're not just building a note-taking app. You're building an evidence-based, educationally-sound learning platform.

Start building. This is your final spec. ğŸš€

# TABLE OF CONTENTS

1. Executive Summary & Vision
2. Product Overview & Positioning
3. 15-Agent Architecture (Complete)
4. UI/UX Architecture (Complete)
5. Purpose-Based System (Complete)
6. Tech Stack & Infrastructure
7. Database Schema
8. 12-Week Implementation Roadmap
9. Step-by-Step Implementation Guide (Phase by Phase)
10. Testing & Quality Assurance
11. Deployment & Launch
12. Success Metrics & KPIs

---

# SECTION 1: EXECUTIVE SUMMARY

## Vision

Build **LearnFlow AI**, a **Knowledge Personalization Engine** that uses 15 specialized AI agents orchestrated by Mastra to transform ANY educational document into personalized learning materialâ€”tailored to each student's language, learning ability, and learning style.

Unlike competitors offering one-size-fits-all solutions, LearnFlow orchestrates agents intelligently based on user PURPOSE (not prescriptive personas), delivers real-time reactive UI updates (<1s), and supports three critical user segments:

1. **Interview & Placement Prep** (Engineering students)
2. **Accessibility & Inclusive Learning** (Students with dyslexia, ADHD)
3. **Language & Cultural Bridge** (Vernacular background students)

## Mission

**Democratize quality education** by removing three critical barriers:

- Language barrier (70% of Indian students study in regional languages)
- Accessibility barrier (3-5% of students with learning disabilities receive ZERO support)
- Efficiency barrier (students waste 50-70% of study time due to inefficient learning formats)

## Target Market

- **Primary:** India (7+ crore students)
- **Secondary:** Global English-speaking + bilingual communities
- **B2B:** Educational institutions, coaching centers

## Expected Outcomes

- âœ… 80% time savings per study session
- âœ… 85%+ comprehension improvement
- âœ… Accessible learning for all ability levels
- âœ… Multi-language support (starting with ENâ†”HI)
- âœ… <1 second reactive updates
- âœ… Production-grade quality

---

# SECTION 2: PRODUCT OVERVIEW & POSITIONING

## Product Name & Tagline

**LearnFlow AI**  
"One Document. Infinite Ways to Learn."

## Positioning

**Knowledge Personalization Engine** powered by 15 specialized AI agents orchestrated intelligently based on user PURPOSE.

## Core Value Proposition

| User Type           | Problem                                       | LearnFlow Solution                                              | Outcome                                                  |
| ------------------- | --------------------------------------------- | --------------------------------------------------------------- | -------------------------------------------------------- |
| **Interview Prep**  | Dense material, limited time                  | Code Agent (Big-O), Quiz Agent (interview Q's), Quick reference | 80% time saved, placement-ready                          |
| **Accessibility**   | Dyslexia/ADHD, zero support                   | Dyslexia fonts, audio, simplification, WCAG AA                  | 66% time saved, GPA +54%, equal access                   |
| **Language Bridge** | English-only education, vernacular background | Hindi translation, bilingual glossary, simplified text          | 60% time saved, 125% comprehension improvement, GPA +36% |

## Key Differentiators

1. **15-Agent Orchestration** (not 1-2 LLM calls)
2. **Real-Time Reactivity** (<1s updates via SSE + Convex)
3. **Purpose-Based Personalization** (not prescriptive personas)
4. **Multi-Language Support** (ENâ†”HI with glossary fidelity)
5. **Built-In Accessibility** (dyslexia, audio, WCAG AA)
6. **Chat-First UI** (CopilotKit + Mastra integrated)
7. **Auto-Detect Intelligence** (smart defaults)
8. **Observable Execution** (full trace, cost tracking)

---

# SECTION 3: 15-AGENT ARCHITECTURE (COMPLETE)

## Agent Overview

### **Tier 1: Orchestration (2 agents)**

#### **Agent 1: Architect Agent** â­â­â­â­â­

**Role:** Meta-level planning and design

**Responsibilities:**

- Analyze complex user requests
- Decompose into logical subtasks
- Identify dependencies
- Select optimal agent sequence
- Plan parallelizable operations
- Estimate resource requirements
- Detect edge cases

**Input:** User request + document + purpose + user context
**Output:** Structured execution plan (DAG JSON)
**LLM:** GPT-4-Turbo
**Cost:** ~$0.02-0.05 per execution

**Implementation Details:**

```typescript
// Input schema
{
  request: string,           // User query
  document_id: string,       // Which document
  purpose: 'interview'|'accessibility'|'language'|'custom'|'auto',
  user_context: {
    history: string[],       // Previous queries
    preferences: object,     // User settings
    reading_level: number    // 6-college
  }
}

// Output schema
{
  phases: Array<{
    name: string,
    agents: Array<{
      agent_name: string,
      sections: number[],
      priority: 'critical'|'high'|'normal',
      persona_weights: object,
      concurrent: boolean
    }>
  }>,
  section_mapping: object,
  estimated_time_ms: number,
  cost_estimate: number
}
```

---

#### **Agent 2: Orchestrator Agent** â­â­â­â­â­

**Role:** Central execution controller

**Responsibilities:**

- Execute Architect's plan
- Route tasks to agents
- Manage parallel execution
- Merge outputs coherently
- Resolve conflicts
- Handle failures with fallbacks
- Monitor progress
- Optimize performance

**Input:** Execution plan + all agents
**Output:** Unified final document
**LLM:** GPT-4-Turbo
**Cost:** ~$0.01-0.03 per document

**Implementation Details:**

```typescript
async function orchestrate(plan, agents) {
  const results = {};

  for (const phase of plan.phases) {
    if (phase.concurrent) {
      // Run in parallel
      const promises = phase.agents.map((agent) =>
        executeAgent(agent, results)
      );
      const outputs = await Promise.all(promises);
      Object.assign(results, mergeOutputs(outputs));
    } else {
      // Run sequentially
      for (const agent of phase.agents) {
        results[agent.name] = await executeAgent(agent, results);
      }
    }
  }

  return mergeAllOutputs(results);
}
```

---

### **Tier 2: Extraction & Organization (3 agents)**

#### **Agent 3: Notes Agent**

**Purpose:** Extract, organize, structure content

**Capabilities:**

- Detect hierarchy (H1-H3)
- Extract key concepts
- Organize by learning flow
- Create summaries per section
- Extract key takeaways

**Output Format:** Markdown with structure
**Cost:** ~$0.01-0.02 per document

---

#### **Agent 4: Diagram Agent**

**Purpose:** Visual representation

**Capabilities:**

- Generate Mermaid diagrams
- Create mind maps
- Generate flowcharts
- Visualize hierarchies
- Annotate with explanations

**Output Format:** Mermaid + SVG
**Cost:** ~$0.01-0.03 per document

---

#### **Agent 5: Summarization Agent**

**Purpose:** Hierarchical multi-granularity summaries

**Capabilities:**

- Auto H1/H2/H3 tree
- 1-sentence / 1-paragraph / 1-page variants
- Key term list (bold) + TL;DR bullets
- Timeline + comparison matrix optional
- Inline citation anchors

**Output Format:** Markdown tree; supports `mode=minimal` for flat summary
**Cost:** ~$0.005-0.01 per document

---

### **Tier 3: Specialized Processing (4 agents)**

#### **Agent 6: Mathematician Agent**

**Purpose:** Mathematical accuracy

**Capabilities:**

- Validate proofs
- Step-by-step solutions
- Alternative methods
- Complexity analysis
- Generate practice problems

**Output Format:** LaTeX + explanations
**Cost:** ~$0.01-0.02 per document

---

#### **Agent 7: Code Agent (Polyglot)**

**Purpose:** Programming support

**Capabilities:**

- Language-agnostic generation
- Big-O analysis
- â‰¥2 edge cases per snippet
- Syntax validation (â‰¥90%)
- Multiple language support

**Output Format:** Code + documentation
**Cost:** ~$0.02-0.04 per document
**KPI:** syntax_ok â‰¥ 90%

---

#### **Agent 8: Research Agent**

**Purpose:** Academic analysis

**Capabilities:**

- Extract methodology
- Critical analysis
- Literature review generation
- Citation network mapping

**Output Format:** Structured analysis
**Cost:** ~$0.01-0.02 per document

---

#### **Agent 9: Technical Diagram Agent**

**Purpose:** Domain-specific diagrams

**Capabilities:**

- Anatomy diagrams
- Circuit diagrams
- System architecture
- UML diagrams

**Output Format:** Technical diagrams
**Cost:** ~$0.02-0.03 per document

---

### **Tier 4: Accessibility & Adaptation (5 agents)**

#### **Agent 10: Accessibility Agent** â­â­â­â­â­

**Purpose:** Make content accessible for ALL learners

**Responsibilities:**

1. **Language Translation**

   - 10+ Indian languages (ENâ†”HI primary)
   - Preserve technical accuracy
   - Bilingual glossary (â‰¥20 terms)

2. **Dyslexia Support**

   - OpenDyslexic font rendering
   - 1.8x line spacing
   - 0.15em letter spacing
   - Left-aligned text
   - Cream background

3. **Audio Generation**

   - TTS conversion (Google Cloud)
   - Speeds: 0.75x, 1.0x, 1.25x, 1.5x
   - SSML word highlighting
   - Sentence-level sync

4. **Reading Level Simplification**

   - Analyze current level (Flesch-Kincaid)
   - Target level: Grade 6-College
   - Replace jargon with definitions
   - Shorter sentences, active voice

5. **ADHD Support**

   - Chunked content (short sections)
   - Visual breaks
   - Summary callouts
   - Progress indicators

6. **Color Enhancement**
   - Importance-based coloring
   - High-contrast themes
   - Colorblind-friendly palettes

**Output Formats:** HTML + CSS, MP3, PDF, EPUB, Accessible web
**Cost:** ~$0.03-0.08 per document
**KPI:** â‰¥40% accessibility feature adoption

---

#### **Agent 11: Quiz & Assessment Agent**

**Purpose:** Generate practice questions

**Capabilities:**

- MCQ + short answer + essay
- Adaptive difficulty
- Bloom's Taxonomy alignment (â‰¥3 levels)
- Auto-grading with feedback
- Spaced repetition scheduling

**Output Format:** JSON + Anki deck
**Cost:** ~$0.01-0.02 per document
**KPI:** 10 MCQ + 5 SA per document minimum

---

#### **Agent 12: Citation & Reference Agent**

**Purpose:** Academic integrity

**Capabilities:**

- Auto-citation (APA, MLA, Chicago, IEEE)
- Source tracking
- Fact verification
- Plagiarism detection
- Bibliography generation

**Output Format:** Citations + bibliography
**Cost:** ~$0.005-0.01 per document

---

#### **Agent 13: Editing Agent**

**Purpose:** User-driven modifications

**Capabilities:**

- Natural language editing
- Bulk operations
- Smart search & replace
- Version diffing
- Undo/redo stack

**Output Format:** Modified content + changelog
**Cost:** ~$0.005-0.01 per edit

---

#### **Agent 14: Analytics Agent**

**Purpose:** Progress tracking and insights

**Capabilities:**

- Time spent per concept
- Comprehension assessment
- Learning curve analysis
- Gap identification
- Recommendation engine
- Progress visualization

**Output Format:** Dashboard data + recommendations
**Cost:** ~$0.005-0.01 per session

---

### **Tier 5: Translation (1 agent)**

#### **Agent 15: Translation Agent (ENâ†”HI)** â­â­â­â­â­

**Purpose:** Bilingual support

**Capabilities:**

- Hindi translation with technical accuracy
- Bilingual toggle â‰¤500ms
- Glossary generation (â‰¥20 terms)
- Bilingual quizzes
- Language fidelity scoring

**Output Format:** Bilingual content + glossary
**Cost:** ~$0.02-0.04 per document
**KPI:** Toggle â‰¤500ms, fidelity â‰¥90%

---

---

## Agent Weights by Purpose

```
AGENT WEIGHTS (0-1.0 scale):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent            â”‚Interview â”‚Accessibâ”‚Language  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Architect        â”‚ 1.0      â”‚ 1.0    â”‚ 1.0      â”‚
â”‚ Orchestrator     â”‚ 1.0      â”‚ 1.0    â”‚ 1.0      â”‚
â”‚ Notes            â”‚ 0.5      â”‚ 0.7    â”‚ 0.8      â”‚
â”‚ Diagram          â”‚ 0.7      â”‚ 0.8    â”‚ 0.6      â”‚
â”‚ Summarization    â”‚ 0.7      â”‚ 0.9    â”‚ 0.7      â”‚
â”‚ Mathematician    â”‚ 0.6      â”‚ 0.3    â”‚ 0.6      â”‚
â”‚ Code             â”‚ 0.9â­    â”‚ 0.2    â”‚ 0.6      â”‚
â”‚ Research         â”‚ 0.4      â”‚ 0.4    â”‚ 0.5      â”‚
â”‚ Tech Diagram     â”‚ 0.6      â”‚ 0.8    â”‚ 0.5      â”‚
â”‚ Accessibility    â”‚ 0.1      â”‚ 1.0â­  â”‚ 0.3      â”‚
â”‚ Quiz             â”‚ 0.9â­    â”‚ 0.8    â”‚ 0.85     â”‚
â”‚ Citation         â”‚ 0.3      â”‚ 0.2    â”‚ 0.3      â”‚
â”‚ Editing          â”‚ 0.5      â”‚ 0.7    â”‚ 0.6      â”‚
â”‚ Analytics        â”‚ 0.6      â”‚ 0.6    â”‚ 0.7      â”‚
â”‚ Translation      â”‚ 0.0      â”‚ 0.0    â”‚ 1.0â­    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â­ = Critical for that purpose
```

---

# SECTION 4: PURPOSE-BASED SYSTEM

## Purpose Options (Instead of Personas)

### **Purpose 1: Interview & Placement Prep**

**For students preparing for:**

- Campus placements
- Coding interviews
- System design rounds
- Competitive programming

**Agent Focus:**

```
CRITICAL (90%+):
- Code Agent: Generate with Big-O + edge cases
- Quiz Agent: Interview-style questions
- Diagram Agent: System design visuals

HIGH (60-80%):
- Summarization Agent: Quick reference
- Mathematician Agent: Algorithm analysis

NORMAL (40-50%):
- Notes Agent: Concise notes
- Research Agent: Paper analysis

LIGHT (0-20%):
- Accessibility Agent: Only if needed
```

**User Gets:**

- âœ… Code examples + Big-O + edge cases
- âœ… 10 MCQ + 5 SA interview questions
- âœ… System design diagrams
- âœ… LeetCode-style problems
- âœ… 2-page cheat sheet
- âœ… Complexity analysis

---

### **Purpose 2: Accessibility & Inclusive Learning**

**For students with:**

- Dyslexia
- ADHD
- Vision impairment
- Learning disabilities

**Agent Focus:**

```
CRITICAL (100%):
- Accessibility Agent: Dyslexia + audio + simplification

HIGH (80-90%):
- Summarization Agent: Concise, scannable
- Quiz Agent: Accessible interface
- Diagram Agent: Clear visuals

NORMAL (60-70%):
- Notes Agent: Clear structure
- Analytics Agent: Progress tracking

LIGHT (0-40%):
- Code Agent: Only if relevant
- Translation Agent: If bilingual user
```

**User Gets:**

- âœ… OpenDyslexic font + 1.8x spacing
- âœ… Audio narration (4 speeds)
- âœ… Color-coded concepts
- âœ… Simplified text (Grade 10Â±1)
- âœ… ADHD-friendly chunking
- âœ… High-contrast themes
- âœ… WCAG AA compliant

---

### **Purpose 3: Language & Cultural Bridge**

**For students:**

- From vernacular backgrounds
- Transitioning to English-medium education
- Building bilingual skills

**Agent Focus:**

```
CRITICAL (100%):
- Translation Agent: ENâ†”HI + bilingual glossary

HIGH (85-90%):
- Quiz Agent: Bilingual quizzes
- Accessibility Agent: Simplification

NORMAL (60-80%):
- Notes Agent: Bilingual notes
- Summarization Agent: Hindi-first summaries
- Analytics Agent: Language progression

LIGHT (40-60%):
- Code Agent: Bilingual comments
- Research Agent: Paper summaries in Hindi
```

**User Gets:**

- âœ… Bilingual toggle â‰¤500ms (EN â†” HI)
- âœ… Hindi explanations + cultural context
- âœ… Bilingual glossary (â‰¥20 terms)
- âœ… Gradual language bridge (EN/HI ratio shifts)
- âœ… Bilingual assessments
- âœ… Language progression tracking

---

### **Purpose 4: Custom Settings (Advanced)**

**For power users:**

**User Controls:**

- Enable/disable each of 15 agents
- Set weight for each agent (0-100%)
- Configure accessibility features
- Set reading level (Grade 6-College)
- Choose language preferences
- Define export formats
- Save as preset

---

### **Purpose 5: Auto-Detect (Smart Default)**

**How It Works:**

```
STEP 1: Analyze document
â”œâ”€ Detect type (coding, textbook, paper, etc.)
â”œâ”€ Measure complexity
â”œâ”€ Identify domain
â””â”€ Check accessibility signals

STEP 2: Check user history
â”œâ”€ Previous purpose selections
â”œâ”€ Feature usage patterns
â”œâ”€ Accessibility adoption
â””â”€ Language preferences

STEP 3: Detect user signals
â”œâ”€ Browser accessibility settings?
â”œâ”€ Zoom level abnormal?
â”œâ”€ Audio output detected?
â””â”€ Mobile vs desktop?

STEP 4: Score each purpose
â”œâ”€ Interview: 0-1.0
â”œâ”€ Accessibility: 0-1.0
â”œâ”€ Language: 0-1.0
â””â”€ Calculate confidence

STEP 5: Recommend
IF confidence > 0.7 THEN
  â†’ Auto-apply best purpose
  â†’ User can override anytime
ELSE
  â†’ Show all options to user
```

---

# SECTION 5: UI/UX ARCHITECTURE (COMPLETE)

## Page Structure

### **Route 1: Landing Page (`/`)**

**Components:**

- Header + Navigation
- Hero section
- Feature showcase (6 cards)
- Purpose selector preview
- Pricing section
- Footer

**Purpose:** Conversion-focused landing

---

### **Route 2: Dashboard (`/dashboard`)**

**Layout:** 3-column

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SIDEBAR   â”‚   MAIN CONTENT   â”‚   RIGHT      â”‚
â”‚ (Collapsible)   (Document Grid)   (Quick Stats)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Sidebar:**

- Current documents
- Chat history
- Collapsible menu
- Search

**Main Content:**

- Purpose selector
- Create new button
- Document grid (3 columns, responsive)
  - AI-generated banner image
  - Document name
  - Created date
  - Actions menu

**Right Panel:**

- Quick stats (documents, time today, etc.)
- Upcoming deadlines

---

### **Route 3: Document Detail (`/dashboard/document/[id]`)**

**Layout:** 3-column (Core Experience)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SIDEBAR   â”‚   CHAT INTERFACE     â”‚   LIVE       â”‚
â”‚             â”‚   (CopilotKit+Mastra) â”‚   PREVIEW    â”‚
â”‚             â”‚                      â”‚              â”‚
â”‚ Current Doc â”‚ User Questions       â”‚ ğŸ“ Notes     â”‚
â”‚ History     â”‚ Agent Responses      â”‚ ğŸ™ï¸ Audio     â”‚
â”‚ Versions    â”‚ Suggestion Chips     â”‚ ğŸ”„ Versions  â”‚
â”‚ Export      â”‚ Input Field          â”‚ ğŸ“Š Analytics â”‚
â”‚ Themes      â”‚                      â”‚              â”‚
â”‚ Settings    â”‚                      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**LEFT SIDEBAR:**

- Current document
- Chat history
- Version history (with rollback)
- Export options (PDF, MD, Anki, HTML)
- Theme selector (5 themes)
- Quick settings (bilingual, audio, accessibility)

**MIDDLE: CHAT INTERFACE**

- Streaming response area
- Agent name + progress indicator
- Suggestion chips (5 context-aware)
- User input field
- Message history

**RIGHT PANEL (Tabbed):**

- **Tab 1: Notes (Live)** - Real-time updating markdown
- **Tab 2: Audio** - TTS player with controls
- **Tab 3: Versions** - Version history with rollback
- **Tab 4: Analytics** - Progress metrics

---

## Responsive Design

**Desktop (1200px+):**

- 3-column visible
- All features
- Full width

**Tablet (768px-1199px):**

- Sidebar collapsible
- Chat + Preview stacked
- Touch-optimized

**Mobile (<768px):**

- Sidebar overlay
- Full-screen chat OR preview
- Tab-based navigation

---

## Component Library (shadcn/ui)

- Button, Card, Dialog, Input, Textarea
- Tabs, Dropdown, Progress, Slider
- Toggle, Badge, Alert, Toast
- Skeleton, ScrollArea, Avatar, Menu

**Custom Components:**

- Chat message (with streaming)
- Suggestion chip
- Document card
- Notes viewer
- Audio player
- Version timeline
- Analytics dashboard
- Sidebar nav

---

# SECTION 6: TECH STACK & INFRASTRUCTURE

## Frontend Stack

```
Framework: Next.js 16 (App Router)
UI Library: React 18
Styling: Tailwind CSS
Components: shadcn/ui (pre-built)
Chat: CopilotKit (UI-to-agent binding)
Real-time: Convex (reactive queries)
Streaming: EventSource (SSE)
Icons: Lucide Icons
Fonts: Google Fonts (Handlee, OpenDyslexic)
```

## Backend Stack

```
API Framework: Next.js 16 App Router
Orchestration: Inngest (durable workflows)
Agents: Mastra (TypeScript agent framework)
LLM Providers: OpenAI, Anthropic, Google
Database: Convex (real-time DB + functions)
File Storage: Cloudflare R2 (cheaper than S3)
Audio: Google Cloud TTS
Image Generation: Replicate or Hugging Face
Validation: Zod (TypeScript schema validation)
Deployment: Vercel (Next.js optimized)
```

## Development Tools

```
Version Control: GitHub
CI/CD: GitHub Actions
Environment: .env.local (local), Vercel (production)
Monitoring: Vercel Analytics
Error Tracking: Sentry
Performance: Vercel Web Analytics
```

## Infrastructure Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Users     â”‚
â”‚  (Browser)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js 16 App        â”‚
â”‚ (Vercel Edge Network)   â”‚
â”‚                         â”‚
â”‚ - API Routes            â”‚
â”‚ - SSE Gateway           â”‚
â”‚ - OAuth/Auth            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend Services      â”‚
â”‚                         â”‚
â”‚ - Inngest (Workflows)   â”‚
â”‚ - Mastra (Agents)       â”‚
â”‚ - OpenAI/Anthropic LLMs â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â”¼â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â†“   â†“   â†“       â†“         â†“
â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚Convexâ”‚ â”‚R2    â”‚ â”‚Googleâ”‚ â”‚External
â”‚(DB)  â”‚ â”‚(File)â”‚ â”‚TTS   â”‚ â”‚APIs
â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
```

---

# SECTION 7: DATABASE SCHEMA

## Convex Database

```typescript
// Users table
export const users = defineTable({
  _id: v.id("users"),
  email: v.string(),
  name: v.string(),
  plan: v.union(v.literal("free"), v.literal("pro"), v.literal("enterprise")),
  purpose_default: v.string(), // 'interview', 'accessibility', 'language', 'auto'
  theme_default_id: v.id("themes"),
  tts_prefs: v.object({
    voice_id: v.string(),
    speed: v.number(), // 0.75, 1.0, 1.25, 1.5
    lang: v.string(), // 'en', 'hi'
  }),
  created_at: v.number(),
  updated_at: v.number(),
});

// Documents table
export const documents = defineTable({
  user_id: v.id("users"),
  title: v.string(),
  pages: v.number(),
  source_key: v.string(), // R2 key
  source_type: v.union(v.literal("pdf"), v.literal("image"), v.literal("docx")),
  ocr_conf_avg: v.number(),
  purpose: v.string(), // Selected purpose
  auto_detected: v.boolean(),
  rights_attested: v.boolean(),
  created_at: v.number(),
  updated_at: v.number(),
}).index("user_id");

// Sections table
export const sections = defineTable({
  doc_id: v.id("documents"),
  idx: v.number(),
  h_path: v.string(), // "1>3>2"
  lang: v.union(v.literal("en"), v.literal("hi")),
  content_md: v.string(),
  summary: v.string(),
  key_takeaways: v.array(v.string()),
  checksum: v.string(),
  version_id: v.id("versions"),
  agent_weights: v.object(),
  created_at: v.number(),
})
  .index("doc_id")
  .index("doc_id", "lang", "idx");

// Runs table (for observability)
export const runs = defineTable({
  doc_id: v.id("documents"),
  type: v.union(v.literal("ingest"), v.literal("regen"), v.literal("export")),
  plan_json: v.string(),
  started_at: v.number(),
  ended_at: v.number(),
  status: v.union(v.literal("ok"), v.literal("error")),
  costs_usd: v.number(),
  error_msg: v.string(),
})
  .index("doc_id")
  .index("started_at");

// Agent steps (per-agent observability)
export const agent_steps = defineTable({
  run_id: v.id("runs"),
  agent: v.string(),
  input_ref: v.string(),
  output_ref: v.string(),
  timings_ms: v.number(),
  retries: v.number(),
  model: v.string(),
  cost_usd: v.number(),
  created_at: v.number(),
}).index("run_id");

// Quizzes table
export const quizzes = defineTable({
  doc_id: v.id("documents"),
  scope: v.union(v.literal("document"), v.literal("section")),
  section_id: v.id("sections"),
  mcq: v.array(
    v.object({
      question: v.string(),
      options: v.array(v.string()),
      correct: v.number(),
      rationale: v.string(),
    })
  ),
  sa: v.array(
    v.object({
      question: v.string(),
      model_answer: v.string(),
    })
  ),
  bloom_levels: v.array(v.string()),
  created_at: v.number(),
});

// Glossary table
export const glossary_terms = defineTable({
  doc_id: v.id("documents"),
  term_en: v.string(),
  def_en: v.string(),
  expl_hi: v.string(),
  fidelity_score: v.number(), // 0-1
  created_at: v.number(),
})
  .index("doc_id")
  .index("term_en");

// Versions table (for rollback)
export const versions = defineTable({
  doc_id: v.id("documents"),
  parent_id: v.id("versions"),
  changed_section_ids: v.array(v.id("sections")),
  purpose: v.string(),
  theme_id: v.id("themes"),
  created_at: v.number(),
})
  .index("doc_id")
  .index("created_at");

// Themes table
export const themes = defineTable({
  user_id: v.id("users"),
  name: v.string(), // 'Minimal', 'Dyslexia', 'Night', 'High-Contrast', 'System'
  tokens: v.object(), // CSS variables {font, spacing, colors}
  is_preset: v.boolean(),
  created_at: v.number(),
})
  .index("user_id")
  .index("name");

// Suggestions table
export const suggestions = defineTable({
  doc_id: v.id("documents"),
  run_id: v.id("runs"),
  items: v.array(
    v.object({
      label: v.string(),
      action: v.string(),
      payload: v.object(),
    })
  ),
  created_at: v.number(),
});

// Exports table
export const exports = defineTable({
  doc_id: v.id("documents"),
  format: v.union(
    v.literal("pdf"),
    v.literal("md"),
    v.literal("anki"),
    v.literal("html")
  ),
  theme_id: v.id("themes"),
  key: v.string(), // R2 key
  status: v.union(v.literal("ok"), v.literal("error")),
  created_at: v.number(),
}).index("doc_id");

// Audit logs (for compliance)
export const audit_logs = defineTable({
  user_id: v.id("users"),
  doc_id: v.id("documents"),
  action: v.string(),
  meta: v.object(),
  created_at: v.number(),
})
  .index("user_id")
  .index("doc_id");

// Cost tracking
export const cost_events = defineTable({
  run_id: v.id("runs"),
  provider: v.string(),
  tokens_in: v.number(),
  tokens_out: v.number(),
  cost_usd: v.number(),
  created_at: v.number(),
}).index("run_id");
```

---

# SECTION 8: 12-WEEK IMPLEMENTATION ROADMAP

## Phase 0: Foundation (Week 1) - Nov 14-20

**Goal:** Setup infrastructure

**Tasks:**

- [ ] Create Next.js 16 project (App Router)
- [ ] Setup Convex database
- [ ] Configure Inngest workflows
- [ ] Setup GitHub repository
- [ ] Configure CI/CD pipeline
- [ ] Setup environment variables
- [ ] Configure authentication (Google OAuth)
- [ ] Deploy to Vercel
- [ ] Setup monitoring (Sentry)

**Deliverables:**

- âœ… Project deployed to production URL
- âœ… Can login with Google
- âœ… Database initialized
- âœ… CI/CD pipeline working

---

## Phase 1: Core Infrastructure (Week 2-3) - Nov 21-Dec 1

### Week 2: UI Foundation + Authentication

**Tasks:**

- [ ] Setup Next.js routing (/, /dashboard, /dashboard/document/[id])
- [ ] Build landing page
- [ ] Implement authentication flows
- [ ] Create sidebar component
- [ ] Create document grid component
- [ ] Setup Tailwind CSS + shadcn/ui

**Deliverables:**

- âœ… Landing page completed
- âœ… Auth flow working
- âœ… Dashboard layout functional
- âœ… Basic UI components built

---

### Week 3: Chat Interface + Real-Time

**Tasks:**

- [ ] Integrate CopilotKit
- [ ] Setup SSE streaming
- [ ] Build chat message component
- [ ] Implement live preview (right panel)
- [ ] Setup Convex real-time queries
- [ ] Build suggestion chip component
- [ ] Implement document upload UI

**Deliverables:**

- âœ… Chat interface functional
- âœ… SSE streaming working
- âœ… Live preview updates in <1s
- âœ… File upload to R2 working

---

## Phase 2: Agent Orchestration (Week 4-6) - Dec 2-15

### Week 4: Architect + Orchestrator Agents

**Tasks:**

- [ ] Setup Mastra framework
- [ ] Implement Architect Agent
  - [ ] Request parsing
  - [ ] DAG generation
  - [ ] Agent selection logic
  - [ ] Weights calculation
- [ ] Implement Orchestrator Agent
  - [ ] Plan execution
  - [ ] Parallel task routing
  - [ ] Output merging
  - [ ] Error handling

**Deliverables:**

- âœ… Architect Agent planning working
- âœ… Orchestrator Agent executing plans
- âœ… DAG visualization in dashboard
- âœ… Agent execution tracing

---

### Week 5: Core Agents (Notes, Diagram, Quiz)

**Tasks:**

- [ ] Implement Notes Agent
  - [ ] Content extraction
  - [ ] Hierarchy detection
  - [ ] Markdown formatting
- [ ] Implement Diagram Agent
  - [ ] Mermaid generation
  - [ ] SVG rendering
- [ ] Implement Quiz Agent
  - [ ] MCQ generation
  - [ ] Bloom's taxonomy tagging

**Deliverables:**

- âœ… 3 core agents working
- âœ… Real-time streaming notes
- âœ… Auto-generated quizzes
- âœ… Diagrams rendering correctly

---

### Week 6: Specialized Agents (Code, Math, Research)

**Tasks:**

- [ ] Implement Code Agent
  - [ ] Multi-language support
  - [ ] Big-O analysis
  - [ ] Edge case generation
  - [ ] Syntax validation (â‰¥90%)
- [ ] Implement Mathematician Agent
  - [ ] Proof validation
  - [ ] Step-by-step solutions
- [ ] Implement Research Agent
  - [ ] Paper analysis
  - [ ] Methodology extraction

**Deliverables:**

- âœ… 6 total agents working
- âœ… Code examples + analysis
- âœ… Mathematical solutions
- âœ… Research paper summaries

---

## Phase 3: Accessibility Layer (Week 7-8) - Dec 16-29

### Week 7: Accessibility Agent (Dyslexia + TTS)

**Tasks:**

- [ ] Implement Accessibility Agent
  - [ ] OpenDyslexic font rendering
  - [ ] 1.8x line spacing logic
  - [ ] Cream background styling
  - [ ] Google Cloud TTS integration
  - [ ] Audio speed controls (4 speeds)
  - [ ] SSML word highlighting
- [ ] Implement Dyslexia CSS module
  - [ ] High-contrast themes
  - [ ] Colorblind-friendly palettes
  - [ ] Reduced motion support

**Deliverables:**

- âœ… Dyslexia formatting working
- âœ… Audio narration functional
- âœ… Synchronized highlighting
- âœ… WCAG AA compliance check passed

---

### Week 8: Translation Agent (ENâ†”HI)

**Tasks:**

- [ ] Implement Translation Agent
  - [ ] Hindi translation
  - [ ] Bilingual toggle UI (â‰¤500ms)
  - [ ] Glossary generation (â‰¥20 terms)
  - [ ] Fidelity scoring
- [ ] Implement bilingual caching
  - [ ] Sentence-level translation cache
  - [ ] Fast toggle performance
- [ ] Build bilingual quiz generator

**Deliverables:**

- âœ… Bilingual toggle working (â‰¤500ms)
- âœ… Hindi translations accurate
- âœ… Glossary fidelity â‰¥90%
- âœ… Bilingual quizzes functional

---

## Phase 4: Export + Versioning (Week 9) - Dec 30-Jan 5

**Tasks:**

- [ ] Implement PDF export
  - [ ] Puppeteer rendering
  - [ ] Mermaid SVG inclusion
  - [ ] Theme preservation
- [ ] Implement Markdown export
  - [ ] Markdown builder
  - [ ] Code formatting
- [ ] Implement Anki export
  - [ ] .apkg generation
  - [ ] Card formatting
- [ ] Implement version history
  - [ ] Version snapshots
  - [ ] Rollback functionality
  - [ ] Diff visualization

**Deliverables:**

- âœ… All 3 export formats working
- âœ… Version history functional
- âœ… Rollback tested
- âœ… Diff viewing working

---

## Phase 5: Performance + Cost Control (Week 10-11) - Jan 6-19

**Tasks:**

- [ ] Performance optimization
  - [ ] TTFB â‰¤1.5s
  - [ ] Streaming â‰¥5 updates/sec
  - [ ] Section regen â‰¤1s first token
- [ ] Cost control implementation
  - [ ] Cost tracking dashboard
  - [ ] Token budgeting per agent
  - [ ] Model tiering (fast/cheap default)
  - [ ] Caching strategy
- [ ] Observability dashboards
  - [ ] Latency metrics
  - [ ] Success rate tracking
  - [ ] Cost p50/p75 monitoring
  - [ ] Agent usage analytics

**Deliverables:**

- âœ… All performance targets met
- âœ… Cost guardrails working
- âœ… Observable dashboards live
- âœ… 99%+ success rate

---

## Phase 6: Beta Launch (Week 12) - Jan 20-26

**Tasks:**

- [ ] Final quality assurance
  - [ ] Cross-browser testing
  - [ ] Mobile responsiveness
  - [ ] Accessibility audit (WCAG AA)
- [ ] Invite beta users (100-500)
- [ ] Setup feedback collection
- [ ] Monitor production metrics
- [ ] Create documentation + help
- [ ] Setup support system

**Deliverables:**

- âœ… 100-500 active beta users
- âœ… NPS â‰¥40
- âœ… <5 critical bugs
- âœ… Ready for public announcement

---

# SECTION 9: STEP-BY-STEP IMPLEMENTATION GUIDE

## Week 1: Foundation Setup

### Step 1.1: Project Initialization

```bash
# Create Next.js 16 project
npx create-next-app@latest learnflow-ai --typescript --tailwind --app

# Install core dependencies
npm install \
  convex \
  inngest \
  mastra \
  next-auth \
  @copilotkit/react \
  zod \
  sentry/nextjs \
  sharp

# Setup Convex
npm run init convex
```

### Step 1.2: Environment Setup

```bash
# Create .env.local
NEXT_PUBLIC_CONVEX_URL=your_convex_url
CONVEX_DEPLOYMENT=prod
INNGEST_EVENT_KEY=your_key
INNGEST_SIGNING_KEY=your_key
OPENAI_API_KEY=your_key
GOOGLE_API_KEY=your_key
CLOUDFLARE_R2_ACCESS_KEY=your_key
CLOUDFLARE_R2_SECRET=your_key
```

### Step 1.3: Database Setup

```typescript
// convex/schema.ts
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  users: defineTable({
    email: v.string(),
    name: v.string(),
    // ... rest of fields
  }).index("email"),

  documents: defineTable({
    user_id: v.id("users"),
    title: v.string(),
    // ... rest of fields
  }).index("user_id"),

  // ... other tables
});
```

### Step 1.4: CI/CD Setup

```yaml
# .github/workflows/deploy.yml
name: Deploy
on:
  push:
    branches: [main]
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: vercel/action@main
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
```

---

## Week 2: UI Foundation

### Step 2.1: Routing Structure

```typescript
// app/page.tsx (Landing)
export default function Home() {
  return <LandingPage />;
}

// app/dashboard/page.tsx (Dashboard)
export default function Dashboard() {
  return <DashboardPage />;
}

// app/dashboard/document/[id]/page.tsx (Detail)
export default function DocumentDetail({ params }) {
  return <DocumentDetailPage id={params.id} />;
}
```

### Step 2.2: Layout Components

```typescript
// components/Sidebar.tsx
export function Sidebar() {
  const [collapsed, setCollapsed] = useState(false);

  return (
    <aside className={`sidebar ${collapsed ? "collapsed" : ""}`}>
      {/* Sidebar content */}
    </aside>
  );
}

// components/ChatInterface.tsx
export function ChatInterface({ docId }) {
  const [messages, setMessages] = useState([]);
  const [streaming, setStreaming] = useState(false);

  return <div className="chat-interface">{/* Chat content */}</div>;
}

// components/LivePreview.tsx
export function LivePreview({ docId }) {
  const notes = useQuery(api.notes.getByDocId, { docId });

  return <div className="live-preview">{/* Preview content */}</div>;
}
```

---

## Week 3: Real-Time Features

### Step 3.1: SSE Streaming Setup

```typescript
// app/api/chat/route.ts
export async function POST(request: Request) {
  const { message, docId } = await request.json();

  const encoder = new TextEncoder();
  let responseStream = new ReadableStream({
    async start(controller) {
      // Get context from Convex
      const context = await getDocumentContext(docId);

      // Stream response from agent
      for await (const chunk of agentStream) {
        controller.enqueue(
          encoder.encode(`data: ${JSON.stringify(chunk)}\n\n`)
        );
      }

      controller.close();
    },
  });

  return new Response(responseStream, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
    },
  });
}
```

### Step 3.2: Frontend SSE Consumer

```typescript
// hooks/useStreamingChat.ts
export function useStreamingChat(docId: string) {
  const [notes, setNotes] = useState("");
  const [streaming, setStreaming] = useState(false);

  async function sendMessage(message: string) {
    setStreaming(true);

    const eventSource = new EventSource(
      `/api/chat?docId=${docId}&message=${encodeURIComponent(message)}`
    );

    eventSource.addEventListener("message", (event) => {
      const chunk = JSON.parse(event.data);
      setNotes((prev) => prev + chunk.text);
    });

    eventSource.addEventListener("end", () => {
      eventSource.close();
      setStreaming(false);
    });
  }

  return { notes, streaming, sendMessage };
}
```

---

## Week 4: Architect Agent Implementation

```typescript
// lib/agents/architect.ts
import { Agent } from 'mastra';
import { openai } from '@ai-sdk/openai';

export const architectAgent = new Agent({
  name: 'Architect',
  model: openai('gpt-4-turbo'),
  tools: [
    parseRequest,
    identifyAgentNeeds,
    generateExecutionPlan,
    estimateResources
  ],
  instructions: `
    You are the Architect Agent. Your job:
    1. Analyze the user request deeply
    2. Identify required agents and their weights
    3. Create optimal execution sequence (DAG)
    4. Estimate time and cost
    5. Detect edge cases

    Output a structured JSON plan.
  `
});

async function parseRequest(request: string) {
  // Parse user request into structured format
  return {
    goal: string,
    constraints: string[],
    preferences: object
  };
}

async function identifyAgentNeeds(request: object) {
  // Determine which agents are needed
  return {
    agents: string[],
    priorities: { [agent: string]: number }
  };
}

async function generateExecutionPlan(agents: string[]) {
  // Create DAG of agent execution
  return {
    phases: Array,
    dependencies: object,
    parallel: string[]
  };
}

async function estimateResources(plan: object) {
  // Estimate time and cost
  return {
    estimated_time_ms: number,
    cost_estimate: number
  };
}
```

---

## (Continuing Similar Pattern for Each Week)

---

# SECTION 10: TESTING & QUALITY ASSURANCE

## Unit Tests

```typescript
// __tests__/agents/architect.test.ts
describe("Architect Agent", () => {
  test("should parse interview prep request", async () => {
    const plan = await architectAgent.run({
      request: "I need BST for interview",
      purpose: "interview",
    });

    expect(plan.phases[0].agents).toContain("Code Agent");
    expect(plan.phases[0].agents).toContain("Quiz Agent");
  });

  test("should detect accessibility needs", async () => {
    const plan = await architectAgent.run({
      request: "Complex math, need help",
      purpose: "accessibility",
    });

    expect(plan.phases[0].agents).toContain("Accessibility Agent");
  });
});
```

## Integration Tests

```typescript
// __tests__/integration/document-flow.test.ts
describe('Document Processing Flow', () => {
  test('should process document end-to-end', async () => {
    // Upload document
    const doc = await uploadDocument({
      file: testPDF,
      purpose: 'interview'
    });

    // Trigger orchestration
    await orchest rateDocument(doc.id);

    // Verify outputs
    const notes = await getNotes(doc.id);
    const quizzes = await getQuizzes(doc.id);

    expect(notes).toBeTruthy();
    expect(quizzes.length).toBeGreaterThanOrEqual(10);
  });
});
```

## E2E Tests (Playwright)

```typescript
// e2e/document.spec.ts
test("user can upload, edit, and export document", async ({ page }) => {
  // Login
  await page.goto("/");
  await page.click("[data-testid=sign-in]");

  // Upload document
  await page.click("[data-testid=create-new]");
  await page.setInputFiles("input[type=file]", "test.pdf");

  // Select purpose
  await page.click("[data-testid=purpose-interview]");

  // Verify streaming
  const notesPanel = page.locator("[data-testid=notes-panel]");
  await expect(notesPanel).toContainText("Binary Search", { timeout: 10000 });

  // Ask question
  await page.fill("[data-testid=chat-input]", "Explain rotations");
  await page.click("[data-testid=send]");

  // Export
  await page.click("[data-testid=export-pdf]");

  const downloadPromise = page.waitForEvent("download");
  const download = await downloadPromise;
  expect(download.suggestedFilename()).toContain(".pdf");
});
```

---

# SECTION 11: DEPLOYMENT & LAUNCH

## Pre-Launch Checklist

```
QUALITY:
- [ ] All tests passing
- [ ] WCAG AA compliance verified
- [ ] Performance targets met (60s p95, 1.5s TTFB)
- [ ] Cost guardrails active
- [ ] Sentry error tracking live

OPERATIONS:
- [ ] Monitoring dashboards setup
- [ ] Alert thresholds configured
- [ ] Backup strategy tested
- [ ] Disaster recovery plan ready
- [ ] 24/7 incident response plan

SECURITY:
- [ ] TLS/HTTPS enforced
- [ ] Rate limiting configured
- [ ] API authentication working
- [ ] Data encryption at rest+transit
- [ ] GDPR compliance verified

MARKETING:
- [ ] Landing page SEO optimized
- [ ] Product Hunt launch prep
- [ ] Media outreach started
- [ ] Social media posts scheduled
- [ ] Beta user testimonials collected
```

## Deployment Steps

```bash
# 1. Final testing
npm run test
npm run e2e

# 2. Build
npm run build

# 3. Deploy to Vercel
git push main
# Automatic deployment via GitHub Actions

# 4. Verify
curl https://learnflow.ai/health

# 5. Monitor
# Check Vercel dashboard, Sentry, monitoring

# 6. Announce
# Launch on Product Hunt, social media, etc.
```

---

# SECTION 12: SUCCESS METRICS & KPIs

## User Engagement Metrics

| Metric                   | Target (Month 3) | Measurement             |
| ------------------------ | ---------------- | ----------------------- |
| DAU (Daily Active Users) | 500              | Convex event logs       |
| MAU (Monthly Active)     | 2000             | User login count        |
| Avg Session Duration     | 15+ min          | Session timestamps      |
| Weekly Active Rate       | â‰¥25%             | MAU / signup count      |
| Monthly Churn Rate       | <5%              | Lost users / prev users |

## Product Quality Metrics

| Metric                      | Target        | How                  |
| --------------------------- | ------------- | -------------------- |
| Document Processing Success | 99%+          | Inngest dashboard    |
| Notes Accuracy              | 95%+          | Manual evaluation    |
| Streaming Latency           | <100ms chunks | Real-time monitoring |
| Uptime                      | 99.5%         | Uptime monitor       |
| E2E Processing Time         | <60s p95      | Inngest metrics      |

## User Satisfaction

| Metric                   | Target                | How             |
| ------------------------ | --------------------- | --------------- |
| Net Promoter Score (NPS) | â‰¥40                   | Monthly survey  |
| App Star Rating          | â‰¥4.5 stars            | App stores      |
| Feature Adoption         | >80% use export       | Analytics       |
| Referral Rate            | >20% new via referral | Signup source   |
| 30-day Retention         | â‰¥50%                  | Cohort analysis |

## Business Metrics

| Metric                          | Month 3 | Month 6   | Month 12   |
| ------------------------------- | ------- | --------- | ---------- |
| Free to Paid Conversion         | 2-3%    | 3-5%      | 5-8%       |
| ARPU (Avg Revenue Per User)     | $2-5    | $5-8      | $10-15     |
| CAC (Customer Acquisition Cost) | <$5     | <$3       | <$2        |
| CLV (Customer Lifetime Value)   | $50-100 | $150-300  | $500-1000  |
| MRR (Monthly Recurring Revenue) | $5k-10k | $50k-100k | $200k-500k |

---

# IMPLEMENTATION CHECKLIST

## Before You Start

- [ ] Team setup (frontend, backend, DevOps)
- [ ] Communication channels (Slack, GitHub)
- [ ] Development environment setup
- [ ] Design system finalized
- [ ] API contracts defined
- [ ] Database schema approved

## Weekly Standup Questions

- [ ] What did we complete this week?
- [ ] What blockers do we have?
- [ ] Are we on track for targets?
- [ ] What's the plan for next week?
- [ ] Any risks we need to address?

## Bi-Weekly Demo

- [ ] Show completed features
- [ ] Demonstrate user flows
- [ ] Discuss metrics/KPIs
- [ ] Get stakeholder feedback
- [ ] Adjust roadmap if needed

---

# CONCLUSION

This is your complete, step-by-step implementation guide for LearnFlow AI.

**You have:**

- âœ… Clear vision and positioning
- âœ… 15-agent architecture with details
- âœ… UI/UX wireframes for every page
- âœ… Purpose-based system (not personas)
- âœ… Complete tech stack
- âœ… Database schema
- âœ… 12-week roadmap
- âœ… Step-by-step implementation
- âœ… Testing strategy
- âœ… Launch plan
- âœ… Success metrics

**Start with Week 1 Foundation. Complete it fully before moving to Week 2.**

**You're ready to build. Let's go.** ğŸš€
